{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import your stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "from pydelfi import delfi\n",
    "from pydelfi import ndes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Set up the simulator\n",
    "This must have the signature `simulator(parameters, seed, args, batch)` -> `np.array([batch, ndata])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from simulators.jla_supernovae import jla_simulator as jla\n",
    "\n",
    "JLASimulator = jla.JLA_Model()\n",
    "\n",
    "def simulator(theta, seed, simulator_args, batch):\n",
    "    \n",
    "    return JLASimulator.simulation(theta, seed)\n",
    "\n",
    "simulator_args = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Set up the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = np.array([0, -1.5, -20, 0, 0, -0.5]).astype(np.float32)\n",
    "upper = np.array([0.6, 0, -18, 1, 6, 0.5]).astype(np.float32)\n",
    "prior = tfd.Blockwise([tfd.Uniform(low=lower[i], high=upper[i]) for i in range(lower.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Set up the compressor\n",
    "Must have the signature `compressor(data, args)` -> `np.array([n_summaries])`<br>\n",
    "In this case we are going to do Gaussian score compression $$\\mathbf{t} = \\boldsymbol\\theta_* + \\mathbf{F}^{-1}\\nabla_\\theta^T\\boldsymbol\\mu_*\\mathbf{C}^{-1}(\\mathbf{d}-\\boldsymbol\\mu_*)$$ using the class `score.Gaussian`. For this we'll need some fiducial parameters, the mean its derivative at the fiducial parameters, the inverse covariance, and the inverse Fisher matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydelfi import score\n",
    "theta_fiducial = np.array([0.2, -0.75, -19.05, 0.125, 2.65, -0.05])\n",
    "\n",
    "mu = JLASimulator.apparent_magnitude(theta_fiducial)\n",
    "Cinv = JLASimulator.Cinv\n",
    "\n",
    "h = np.array(abs(theta_fiducial))*0.01\n",
    "dmudt = JLASimulator.dmudt(theta_fiducial, h)\n",
    "\n",
    "Compressor = score.Gaussian(len(JLASimulator.data), theta_fiducial, mu = mu, Cinv = Cinv, dmudt = dmudt)\n",
    "Compressor.compute_fisher()\n",
    "Finv = Compressor.Finv\n",
    "\n",
    "def compressor(d, compressor_args):\n",
    "    return Compressor.scoreMLE(d)\n",
    "compressor_args=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load in the compressed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_data = compressor(JLASimulator.data, compressor_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define ensemble of NDEs\n",
    "\n",
    "For this example let's define a stack of 6 NDEs; one Masked Autoregressive Flow (MAF) and five Mixture Density Networks (MDNs) with 1-5 full-rank Gaussian components respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDEs = [ndes.ConditionalMADE(\n",
    "            n_parameters=6,\n",
    "            n_data=6,\n",
    "            n_hidden=[50,50], \n",
    "            activation=tf.tanh, \n",
    "            all_layers=False) for i in range(3)]\n",
    "\n",
    "#NDEs = [ndes.ConditionalMaskedAutoregressiveFlow(\n",
    "#            n_parameters=6,\n",
    "#            n_data=6,\n",
    "#            n_mades=5,\n",
    "#            n_hidden=[50,50], \n",
    "#            activation=tf.tanh, \n",
    "#            all_layers=True)]\n",
    "\n",
    "NDEs += [ndes.MixtureDensityNetwork(\n",
    "            n_parameters=6,\n",
    "            n_data=6, \n",
    "            n_components=i+1,\n",
    "            n_hidden=[50,50], \n",
    "            activation=tf.tanh)\n",
    "        for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create DELFI object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble = delfi.Delfi(compressed_data, prior, NDEs, \n",
    "                            Finv=Finv, \n",
    "                            theta_fiducial=theta_fiducial, \n",
    "                            param_names=['\\\\Omega_m', 'w_0', 'M_\\mathrm{B}', '\\\\alpha', '\\\\beta', '\\\\delta M'], \n",
    "                            results_dir=\"simulators/jla_supernovae/results\",\n",
    "                            filename=\"jla\",\n",
    "                            optimiser=tf.keras.optimizers.Adam,\n",
    "                            optimiser_arguments=None,\n",
    "                            dtype=tf.float32,\n",
    "                            posterior_chain_length=100,\n",
    "                            input_normalization=\"fisher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fisher pre-training to initialize the NDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble.fisher_pretraining(n_batch=5000, epochs=1000, patience=15, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sequential Neural Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_initial = 200\n",
    "n_batch = 200\n",
    "n_populations = 10\n",
    "\n",
    "DelfiEnsemble.sequential_training(simulator, compressor, n_initial, n_batch, n_populations, patience=20, plot=True, save_intermediate_posteriors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample the learned posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples, posterior_weights, log_posterior_values = DelfiEnsemble.emcee_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alright let's plot it!\n",
    "Feed it a list of `(n_samples, n_parameters)` arrays for making a triangle plot; in this case let's just plot the posterior samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble.triangle_plot(samples=[posterior_samples], weights=[posterior_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 123456\n",
    "float(\"{0:.3g}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(1200, 1, 5)\n",
    "np.array2string(x, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_batch= 5000\n",
    "# Broader proposal\n",
    "proposal = tfd.TruncatedMultivariateNormalTriL(\n",
    "    loc=DelfiEnsemble.theta_fiducial, scale_tril=tf.linalg.cholesky(9*DelfiEnsemble.Finv),\n",
    "    low=DelfiEnsemble.prior.low, high=DelfiEnsemble.prior.high,\n",
    "    validate_args=False, allow_nan_stats=True,\n",
    "    name='AsymptoticPosterior')\n",
    "\n",
    "# Cholesky of inverse Fisher information matrix\n",
    "L = np.linalg.cholesky(DelfiEnsemble.Finv)\n",
    "\n",
    "# Sample parameters from some broad proposal\n",
    "theta_batch = np.zeros((3*n_batch, DelfiEnsemble.npar))\n",
    "theta_batch[:n_batch,:] = DelfiEnsemble.prior.sample(n_batch)\n",
    "theta_batch[n_batch:2*n_batch,:] = DelfiEnsemble.asymptotic_posterior.sample(n_batch)\n",
    "theta_batch[2*n_batch:,:] = proposal.sample(n_batch)\n",
    "\n",
    "# Sample data assuming a Gaussian likelihood\n",
    "data_batch = np.array([theta + np.dot(L, np.random.normal(0, 1, DelfiEnsemble.npar)) for theta in theta_batch], dtype=np.float32)\n",
    "\n",
    "# Construct the initial training-set\n",
    "fisher_theta_train = (theta_batch.astype(np.float32).reshape((3*n_batch, DelfiEnsemble.npar)) - DelfiEnsemble.theta_shift)/DelfiEnsemble.theta_scale\n",
    "fisher_data_train = (data_batch.astype(np.float32).reshape((3*n_batch, DelfiEnsemble.npar)) - DelfiEnsemble.data_shift)/DelfiEnsemble.data_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_theta_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(fisher_data_train[:,-1], bins=80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = DelfiEnsemble.asymptotic_posterior.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(x[:,1], bins=80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble.posterior_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, weights, log_prob = DelfiEnsemble.emcee_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble.prior.log_prob(theta_fiducial.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble.NDEs.weighted_log_prob((compressed_data.astype(np.float32) - DelfiEnsemble.data_shift)/DelfiEnsemble.data_scale, conditional=(theta_fiducial.astype(np.float32) - DelfiEnsemble.theta_shift)/DelfiEnsemble.theta_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDEs[0].log_prob(tf.convert_to_tensor((compressed_data - theta_fiducial)/DelfiEnsemble.fisher_errors, dtype=tf.float32), conditional=tf.convert_to_tensor((compressed_data - theta_fiducial)/DelfiEnsemble.fisher_errors, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
