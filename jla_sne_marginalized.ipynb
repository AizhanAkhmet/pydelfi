{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as interpolate\n",
    "import simulators.jla_supernovae.jla_simulator as jla\n",
    "import ndes.ndes as ndes\n",
    "import delfi.delfi as delfi\n",
    "import compression.score.score as score\n",
    "import distributions.priors as priors\n",
    "import tensorflow as tf\n",
    "from scipy.linalg import block_diag\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET UP THE PRIOR ###\n",
    "\n",
    "# Prior over theta (interesting parameters)\n",
    "lower = np.array([0, -1.5])\n",
    "upper = np.array([0.6, 0])\n",
    "prior_covariance = np.diag([0.4, 0.75])**2\n",
    "prior_covariance[0,1] = prior_covariance[1,0] = -0.8*0.4*0.75\n",
    "prior_mean = np.array([  0.3  ,  -0.75])\n",
    "prior = priors.TruncatedGaussian(prior_mean, prior_covariance, lower, upper)\n",
    "\n",
    "# Prior over eta (nuisances)\n",
    "eta_lower = np.array([-20, 0, 0, -0.5])\n",
    "eta_upper = np.array([-18, 1, 6, 0.5])\n",
    "eta_mean = np.array([-19.05 ,   0.125,   2.6  ,  -0.05 ])\n",
    "eta_covariance = np.diag([0.1, 0.025, 0.25, 0.05])**2\n",
    "eta_prior = priors.TruncatedGaussian(eta_mean, eta_covariance, eta_lower, eta_upper)\n",
    "\n",
    "# Joint prior over nuisances and interesting parameters\n",
    "joint_lower = np.concatenate([lower, eta_lower])\n",
    "joint_upper = np.concatenate([upper, eta_upper])\n",
    "joint_mean = np.concatenate([prior_mean, eta_mean])\n",
    "joint_covariance = block_diag(prior_covariance, eta_covariance)\n",
    "joint_prior = priors.TruncatedGaussian(joint_mean, \n",
    "                                       joint_covariance,\n",
    "                                       joint_lower,\n",
    "                                       joint_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET UP FOR SIMULATION CODE ###\n",
    "\n",
    "JLASimulator = jla.JLA_Model()\n",
    "\n",
    "# Simulator function: This must be of the form simulator(theta, seed, args) -> simulated data vector\n",
    "def simulator(theta, seed, simulator_args, batch):\n",
    "    \n",
    "    # Draw nuisances from prior\n",
    "    eta_prior = simulator_args[0]\n",
    "    eta = eta_prior.draw()\n",
    "    \n",
    "    return JLASimulator.simulation(np.concatenate([theta, eta]), seed)\n",
    "\n",
    "# Arguments for simulator\n",
    "simulator_args = [eta_prior]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET UP THE COMPRESSOR ###\n",
    "\n",
    "# Fiducial parameters\n",
    "theta_fiducial = np.array([0.20181324,  -0.74762939])\n",
    "eta_fiducial = np.array([-19.04253368,   0.12566322,   2.64387045, -0.05252869])\n",
    "\n",
    "# Expected data (mean) and covariance\n",
    "mu = JLASimulator.apparent_magnitude(np.concatenate([theta_fiducial, eta_fiducial]))\n",
    "Cinv = JLASimulator.Cinv\n",
    "\n",
    "# Calculate derivatives of the expected power spectrum\n",
    "h = np.array(abs(np.concatenate([theta_fiducial, eta_fiducial])))*0.01\n",
    "dmudt = JLASimulator.dmudt(np.concatenate([theta_fiducial, eta_fiducial]), h)\n",
    "\n",
    "# Define compression as score-MLE of a Wishart likelihood\n",
    "Compressor = score.Gaussian(len(JLASimulator.data), np.concatenate([theta_fiducial, eta_fiducial]), mu = mu, Cinv = Cinv, dmudt = dmudt, prior_mean = joint_mean, prior_covariance = joint_covariance)\n",
    "\n",
    "# Compute the Fisher matrix\n",
    "Compressor.compute_fisher()\n",
    "\n",
    "# Pull out Fisher matrix inverse\n",
    "Finv = Compressor.Finv[0:2,0:2]\n",
    "\n",
    "# Compressor function: This must have the form compressor(data, args) -> compressed summaries (pseudoMLE)\n",
    "def compressor(d, compressor_args):\n",
    "    return Compressor.projected_scoreMLE(d, np.arange(2,6))\n",
    "compressor_args = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compress the JLA data ###\n",
    "compressed_data = compressor(JLASimulator.data, compressor_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble of NDEs\n",
    "NDEs = [ndes.ConditionalMaskedAutoregressiveFlow(n_parameters=2, n_data=2, n_hiddens=[50,50], n_mades=5, act_fun=tf.tanh, index=0),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=2, n_data=2, n_components=1, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=1),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=2, n_data=2, n_components=2, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=2),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=2, n_data=2, n_components=3, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=3),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=2, n_data=2, n_components=4, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=4),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=2, n_data=2, n_components=5, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=5)]\n",
    "\n",
    "\n",
    "# Create the DELFI object\n",
    "DelfiEnsemble = delfi.Delfi(compressed_data, prior, NDEs, Finv = Finv, theta_fiducial = theta_fiducial, \n",
    "                       param_limits = [lower, upper],\n",
    "                       param_names = ['\\Omega_m', 'w_0'], \n",
    "                       results_dir = \"simulators/jla_supernovae/results_marginal/\",\n",
    "                       input_normalization=\"fisher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the Fisher pre-training\n",
    "DelfiEnsemble.fisher_pretraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial samples, batch size for population samples, number of populations\n",
    "n_initial = 100\n",
    "n_batch = 100\n",
    "n_populations = 11\n",
    "\n",
    "# Do the SNL training\n",
    "DelfiEnsemble.sequential_training(simulator, compressor, n_initial, n_batch, n_populations, patience=10, simulator_args=simulator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
